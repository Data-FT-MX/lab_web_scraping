{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib\n",
    "import numpy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "# from pprint import pprint\n",
    "# from lxml import html\n",
    "# from lxml.html import fromstring\n",
    "# import urllib.request\n",
    "# from urllib.request import urlopen\n",
    "# import random\n",
    "# import re\n",
    "# import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "\n",
    "response = requests.get(url)\n",
    "http = urllib.request.Request(url)\n",
    "http\n",
    "response\n",
    "html = response. content\n",
    "soup = BeautifulSoup(html, 'lxml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Joe Chen',\n",
       " 'Adam Johnson',\n",
       " 'Trask Stalnaker',\n",
       " 'Markus Olsson',\n",
       " 'Rich Harris',\n",
       " 'William Candillon',\n",
       " 'Remi Rousselet',\n",
       " 'Saurav Mukherjee',\n",
       " 'Felix Angelov',\n",
       " 'mrdoob',\n",
       " 'Zac Bergquist',\n",
       " 'Franck Nijhof',\n",
       " 'Anthony Fu',\n",
       " 'Zihua Li',\n",
       " 'Geoff Bourne',\n",
       " 'LoveSy',\n",
       " 'Lucas Fernandes Nogueira',\n",
       " 'Jelle Zijlstra',\n",
       " 'Robert Mosolgo',\n",
       " 'Andrew Kane',\n",
       " 'Shivam Mathur',\n",
       " 'Tim Holy',\n",
       " 'Qiusheng Wu',\n",
       " 'David Tolnay',\n",
       " 'Takashi Kokubun']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = soup.select('div h1[class=\"h3 lh-condensed\"]')\n",
    "name2 = [element.text for element in names]\n",
    "clean_name2 = [text.strip() for text in name2]\n",
    "clean_name2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#your code\n",
    "response = requests.get(url)\n",
    "http = urllib.request.Request(url)\n",
    "http\n",
    "response\n",
    "html = response. content\n",
    "soup = BeautifulSoup(html, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FeeiCN /      Security-PPT',\n",
       " 'public-apis /      public-apis',\n",
       " 'donnemartin /      system-design-primer',\n",
       " 'TheAlgorithms /      Python',\n",
       " 'microsoft /      unilm',\n",
       " 'streamlit /      streamlit',\n",
       " 'mxrch /      GHunt',\n",
       " 'pandas-dev /      pandas',\n",
       " 'PyTorchLightning /      pytorch-lightning',\n",
       " 'YuliangXiu /      ICON',\n",
       " 'open-mmlab /      mmaction2',\n",
       " 'huggingface /      transformers',\n",
       " 'Azure /      azure-cli',\n",
       " 'dagster-io /      dagster',\n",
       " 'spack /      spack',\n",
       " 'ansible /      awx',\n",
       " 'nvbn /      thefuck',\n",
       " 'apache /      tvm',\n",
       " 'cloud-custodian /      cloud-custodian',\n",
       " 'samuelcolvin /      pydantic',\n",
       " 'saltstack /      salt',\n",
       " 'Jxck-S /      plane-notify',\n",
       " 'dbt-labs /      dbt-core',\n",
       " 'open-mmlab /      mmdetection',\n",
       " 'EleutherAI /      gpt-neox']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos = soup.select('div h1[class=\"h3 lh-condensed\"]')\n",
    "repos1 = [element.text for element in repos]\n",
    "clean_repos = [text.strip().replace('\\n', '') for text in repos1]\n",
    "clean_repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "response = requests.get(url)\n",
    "http = urllib.request.Request(url)\n",
    "http\n",
    "response\n",
    "html = response. content\n",
    "soup = BeautifulSoup(html, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = soup.select('img')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_src = [element['src'] for element in image]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "http = urllib.request.Request(url)\n",
    "http\n",
    "response\n",
    "html = response. content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/Pythonidae',\n",
       " '/wiki/Python_(genus)',\n",
       " '#Computing',\n",
       " '#People',\n",
       " '#Roller_coasters',\n",
       " '#Vehicles',\n",
       " '#Weaponry',\n",
       " '#Other_uses',\n",
       " '#See_also',\n",
       " '/wiki/Python_(programming_language)',\n",
       " '/wiki/CMU_Common_Lisp',\n",
       " '/wiki/PERQ#PERQ_3',\n",
       " '/wiki/Python_of_Aenus',\n",
       " '/wiki/Python_(painter)',\n",
       " '/wiki/Python_of_Byzantium',\n",
       " '/wiki/Python_of_Catana',\n",
       " '/wiki/Python_Anghelo',\n",
       " '/wiki/Python_(Efteling)',\n",
       " '/wiki/Python_(Busch_Gardens_Tampa_Bay)',\n",
       " '/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)',\n",
       " '/wiki/Python_(automobile_maker)',\n",
       " '/wiki/Python_(Ford_prototype)',\n",
       " '/wiki/Python_(missile)',\n",
       " '/wiki/Python_(nuclear_primary)',\n",
       " '/wiki/Colt_Python',\n",
       " '/wiki/PYTHON',\n",
       " '/wiki/Python_(film)',\n",
       " '/wiki/Python_(mythology)',\n",
       " '/wiki/Monty_Python',\n",
       " '/wiki/Python_(Monty)_Pictures',\n",
       " '/wiki/Timon_of_Phlius',\n",
       " '/wiki/Cython',\n",
       " '/wiki/Pithon',\n",
       " '/wiki/Category:Disambiguation_pages',\n",
       " '/wiki/Category:Human_name_disambiguation_pages',\n",
       " '/wiki/Category:Disambiguation_pages_with_given-name-holder_lists',\n",
       " '/wiki/Category:Disambiguation_pages_with_short_descriptions',\n",
       " '/wiki/Category:Short_description_is_different_from_Wikidata',\n",
       " '/wiki/Category:All_article_disambiguation_pages',\n",
       " '/wiki/Category:All_disambiguation_pages',\n",
       " '/wiki/Category:Animal_common_name_disambiguation_pages',\n",
       " '/wiki/Special:MyTalk',\n",
       " '/wiki/Special:MyContributions',\n",
       " '/w/index.php?title=Special:CreateAccount&returnto=Python',\n",
       " '/w/index.php?title=Special:UserLogin&returnto=Python',\n",
       " '/wiki/Python',\n",
       " '/wiki/Talk:Python',\n",
       " '/wiki/Python',\n",
       " '/w/index.php?title=Python&action=edit',\n",
       " '/w/index.php?title=Python&action=history',\n",
       " '/wiki/Main_Page',\n",
       " '/wiki/Wikipedia:Contents',\n",
       " '/wiki/Portal:Current_events',\n",
       " '/wiki/Special:Random',\n",
       " '/wiki/Wikipedia:About',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " 'https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en',\n",
       " '/wiki/Help:Contents',\n",
       " '/wiki/Help:Introduction',\n",
       " '/wiki/Wikipedia:Community_portal',\n",
       " '/wiki/Special:RecentChanges',\n",
       " '/wiki/Wikipedia:File_Upload_Wizard',\n",
       " '/wiki/Special:WhatLinksHere/Python',\n",
       " '/wiki/Special:RecentChangesLinked/Python',\n",
       " '/wiki/Wikipedia:File_Upload_Wizard',\n",
       " '/wiki/Special:SpecialPages',\n",
       " '/w/index.php?title=Python&oldid=1071027391',\n",
       " '/w/index.php?title=Python&action=info',\n",
       " '/w/index.php?title=Special:CiteThisPage&page=Python&id=1071027391&wpFormIdentifier=titleform',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452',\n",
       " '/w/index.php?title=Special:DownloadAsPdf&page=Python&action=show-download-screen',\n",
       " '/w/index.php?title=Python&printable=yes',\n",
       " 'https://commons.wikimedia.org/wiki/Category:Python',\n",
       " 'https://af.wikipedia.org/wiki/Python',\n",
       " 'https://als.wikipedia.org/wiki/Python',\n",
       " 'https://ar.wikipedia.org/wiki/%D8%A8%D8%A7%D9%8A%D8%AB%D9%88%D9%86_(%D8%AA%D9%88%D8%B6%D9%8A%D8%AD)',\n",
       " 'https://az.wikipedia.org/wiki/Python',\n",
       " 'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)',\n",
       " 'https://be.wikipedia.org/wiki/Python',\n",
       " 'https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)',\n",
       " 'https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)',\n",
       " 'https://da.wikipedia.org/wiki/Python',\n",
       " 'https://de.wikipedia.org/wiki/Python',\n",
       " 'https://eo.wikipedia.org/wiki/Pitono_(apartigilo)',\n",
       " 'https://eu.wikipedia.org/wiki/Python_(argipena)',\n",
       " 'https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86',\n",
       " 'https://fr.wikipedia.org/wiki/Python',\n",
       " 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0',\n",
       " 'https://hr.wikipedia.org/wiki/Python_(razdvojba)',\n",
       " 'https://io.wikipedia.org/wiki/Pitono',\n",
       " 'https://id.wikipedia.org/wiki/Python',\n",
       " 'https://ia.wikipedia.org/wiki/Python_(disambiguation)',\n",
       " 'https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)',\n",
       " 'https://it.wikipedia.org/wiki/Python_(disambigua)',\n",
       " 'https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F',\n",
       " 'https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)',\n",
       " 'https://kg.wikipedia.org/wiki/Mboma_(nyoka)',\n",
       " 'https://la.wikipedia.org/wiki/Python_(discretiva)',\n",
       " 'https://lb.wikipedia.org/wiki/Python',\n",
       " 'https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)',\n",
       " 'https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)',\n",
       " 'https://nl.wikipedia.org/wiki/Python',\n",
       " 'https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3',\n",
       " 'https://no.wikipedia.org/wiki/Pyton',\n",
       " 'https://pl.wikipedia.org/wiki/Pyton',\n",
       " 'https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)',\n",
       " 'https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)',\n",
       " 'https://sk.wikipedia.org/wiki/Python',\n",
       " 'https://sr.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%B2%D0%B8%D1%88%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%BD%D0%B0_%D0%BE%D0%B4%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D1%86%D0%B0)',\n",
       " 'https://sh.wikipedia.org/wiki/Python',\n",
       " 'https://fi.wikipedia.org/wiki/Python',\n",
       " 'https://sv.wikipedia.org/wiki/Pyton',\n",
       " 'https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99',\n",
       " 'https://tr.wikipedia.org/wiki/Python_(anlam_ayr%C4%B1m%C4%B1)',\n",
       " 'https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD',\n",
       " 'https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86',\n",
       " 'https://vi.wikipedia.org/wiki/Python',\n",
       " 'https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License',\n",
       " '//creativecommons.org/licenses/by-sa/3.0/',\n",
       " '//foundation.wikimedia.org/wiki/Terms_of_Use',\n",
       " '//foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " '//www.wikimediafoundation.org/',\n",
       " 'https://foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " '/wiki/Wikipedia:About',\n",
       " '/wiki/Wikipedia:General_disclaimer',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " '//en.m.wikipedia.org/w/index.php?title=Python&mobileaction=toggle_view_mobile',\n",
       " 'https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute',\n",
       " 'https://stats.wikimedia.org/#/en.wikipedia.org',\n",
       " 'https://foundation.wikimedia.org/wiki/Cookie_statement',\n",
       " 'https://wikimediafoundation.org/',\n",
       " 'https://www.mediawiki.org/']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')\n",
    "python_links = soup.select (\"li > a\")\n",
    "links = [link['href'] for link in python_links]\n",
    "links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "response = requests.get(url)\n",
    "http = urllib.request.Request(url)\n",
    "http\n",
    "response\n",
    "html = response. content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup.select('div.usctitle')\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title2 = [element.text for element in title]\n",
    "clean_title = [text.strip() for text in title2]\n",
    "clean_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "http = urllib.request.Request(url)\n",
    "http\n",
    "response\n",
    "html = response. content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "table = pd.read_html(html)\n",
    "\n",
    "len(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">CitizenResponse</th>\n",
       "      <th>Date &amp; Time UTC</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Latitude degrees</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Longitude degrees</th>\n",
       "      <th>Depth km</th>\n",
       "      <th>Mag [+]</th>\n",
       "      <th>Region name [+]</th>\n",
       "      <th>Last update [-]</th>\n",
       "      <th>Unnamed: 12_level_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910».1</th>\n",
       "      <th>12345678910».2</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910».1</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910».1</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910»</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 23:55:25.017min ago</td>\n",
       "      <td>24.65</td>\n",
       "      <td>S</td>\n",
       "      <td>68.87</td>\n",
       "      <td>W</td>\n",
       "      <td>124</td>\n",
       "      <td>M</td>\n",
       "      <td>2.7</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "      <td>2022-03-05 00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 23:52:36.420min ago</td>\n",
       "      <td>37.97</td>\n",
       "      <td>N</td>\n",
       "      <td>121.90</td>\n",
       "      <td>W</td>\n",
       "      <td>3</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SAN FRANCISCO BAY AREA, CALIF.</td>\n",
       "      <td>2022-03-04 23:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 23:46:33.026min ago</td>\n",
       "      <td>6.95</td>\n",
       "      <td>S</td>\n",
       "      <td>130.61</td>\n",
       "      <td>E</td>\n",
       "      <td>109</td>\n",
       "      <td>mb</td>\n",
       "      <td>4.7</td>\n",
       "      <td>BANDA SEA</td>\n",
       "      <td>2022-03-05 00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 23:13:42.459min ago</td>\n",
       "      <td>36.35</td>\n",
       "      <td>N</td>\n",
       "      <td>14.78</td>\n",
       "      <td>E</td>\n",
       "      <td>13</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.4</td>\n",
       "      <td>SICILY, ITALY</td>\n",
       "      <td>2022-03-04 23:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 22:54:58.21hr 18min ago</td>\n",
       "      <td>36.61</td>\n",
       "      <td>N</td>\n",
       "      <td>121.07</td>\n",
       "      <td>W</td>\n",
       "      <td>9</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "      <td>2022-03-04 22:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 22:39:16.11hr 33min ago</td>\n",
       "      <td>19.19</td>\n",
       "      <td>N</td>\n",
       "      <td>155.51</td>\n",
       "      <td>W</td>\n",
       "      <td>36</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.5</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2022-03-04 22:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IV</td>\n",
       "      <td>2022-03-04 22:32:46.01hr 40min ago</td>\n",
       "      <td>45.40</td>\n",
       "      <td>N</td>\n",
       "      <td>16.32</td>\n",
       "      <td>E</td>\n",
       "      <td>8</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.1</td>\n",
       "      <td>CROATIA</td>\n",
       "      <td>2022-03-04 22:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 22:31:36.11hr 41min ago</td>\n",
       "      <td>38.77</td>\n",
       "      <td>N</td>\n",
       "      <td>122.72</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "      <td>2022-03-04 22:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 22:31:31.11hr 41min ago</td>\n",
       "      <td>18.02</td>\n",
       "      <td>N</td>\n",
       "      <td>66.76</td>\n",
       "      <td>W</td>\n",
       "      <td>13</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>2022-03-04 22:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 22:29:45.11hr 43min ago</td>\n",
       "      <td>39.63</td>\n",
       "      <td>N</td>\n",
       "      <td>143.70</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>Mw</td>\n",
       "      <td>5.1</td>\n",
       "      <td>OFF EAST COAST OF HONSHU, JAPAN</td>\n",
       "      <td>2022-03-04 23:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 22:28:35.01hr 44min ago</td>\n",
       "      <td>40.48</td>\n",
       "      <td>S</td>\n",
       "      <td>72.14</td>\n",
       "      <td>W</td>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>2.6</td>\n",
       "      <td>LOS LAGOS, CHILE</td>\n",
       "      <td>2022-03-04 22:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 22:28:07.11hr 44min ago</td>\n",
       "      <td>35.74</td>\n",
       "      <td>N</td>\n",
       "      <td>3.47</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.2</td>\n",
       "      <td>STRAIT OF GIBRALTAR</td>\n",
       "      <td>2022-03-04 22:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 22:26:09.81hr 46min ago</td>\n",
       "      <td>44.64</td>\n",
       "      <td>N</td>\n",
       "      <td>7.42</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NORTHERN ITALY</td>\n",
       "      <td>2022-03-04 22:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 22:20:50.01hr 52min ago</td>\n",
       "      <td>7.82</td>\n",
       "      <td>S</td>\n",
       "      <td>118.63</td>\n",
       "      <td>E</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>3.8</td>\n",
       "      <td>FLORES SEA</td>\n",
       "      <td>2022-03-04 22:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 21:59:29.02hr 13min ago</td>\n",
       "      <td>31.44</td>\n",
       "      <td>S</td>\n",
       "      <td>69.17</td>\n",
       "      <td>W</td>\n",
       "      <td>113</td>\n",
       "      <td>M</td>\n",
       "      <td>4.1</td>\n",
       "      <td>SAN JUAN, ARGENTINA</td>\n",
       "      <td>2022-03-04 22:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 21:58:42.12hr 14min ago</td>\n",
       "      <td>39.20</td>\n",
       "      <td>N</td>\n",
       "      <td>16.69</td>\n",
       "      <td>E</td>\n",
       "      <td>18</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.5</td>\n",
       "      <td>SOUTHERN ITALY</td>\n",
       "      <td>2022-03-04 22:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 21:53:43.02hr 19min ago</td>\n",
       "      <td>8.05</td>\n",
       "      <td>S</td>\n",
       "      <td>120.54</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>3.9</td>\n",
       "      <td>FLORES REGION, INDONESIA</td>\n",
       "      <td>2022-03-04 22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 21:43:52.82hr 29min ago</td>\n",
       "      <td>36.53</td>\n",
       "      <td>N</td>\n",
       "      <td>121.11</td>\n",
       "      <td>W</td>\n",
       "      <td>6</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.1</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "      <td>2022-03-04 21:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 21:40:57.02hr 32min ago</td>\n",
       "      <td>30.43</td>\n",
       "      <td>S</td>\n",
       "      <td>71.83</td>\n",
       "      <td>W</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>3.7</td>\n",
       "      <td>OFFSHORE COQUIMBO, CHILE</td>\n",
       "      <td>2022-03-04 22:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 21:38:38.42hr 34min ago</td>\n",
       "      <td>35.50</td>\n",
       "      <td>N</td>\n",
       "      <td>3.67</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.3</td>\n",
       "      <td>STRAIT OF GIBRALTAR</td>\n",
       "      <td>2022-03-04 22:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 21:25:05.12hr 48min ago</td>\n",
       "      <td>35.60</td>\n",
       "      <td>N</td>\n",
       "      <td>120.27</td>\n",
       "      <td>W</td>\n",
       "      <td>12</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.3</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "      <td>2022-03-04 21:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 21:19:54.52hr 53min ago</td>\n",
       "      <td>45.80</td>\n",
       "      <td>N</td>\n",
       "      <td>9.10</td>\n",
       "      <td>E</td>\n",
       "      <td>39</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NORTHERN ITALY</td>\n",
       "      <td>2022-03-04 21:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>III</td>\n",
       "      <td>2022-03-04 21:17:52.42hr 55min ago</td>\n",
       "      <td>38.64</td>\n",
       "      <td>N</td>\n",
       "      <td>15.62</td>\n",
       "      <td>E</td>\n",
       "      <td>174</td>\n",
       "      <td>mb</td>\n",
       "      <td>4.4</td>\n",
       "      <td>SICILY, ITALY</td>\n",
       "      <td>2022-03-04 22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 21:09:45.03hr 03min ago</td>\n",
       "      <td>29.54</td>\n",
       "      <td>S</td>\n",
       "      <td>71.60</td>\n",
       "      <td>W</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>2.7</td>\n",
       "      <td>OFFSHORE COQUIMBO, CHILE</td>\n",
       "      <td>2022-03-04 21:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 21:05:59.13hr 07min ago</td>\n",
       "      <td>17.96</td>\n",
       "      <td>N</td>\n",
       "      <td>66.85</td>\n",
       "      <td>W</td>\n",
       "      <td>13</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>2022-03-04 21:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 21:03:49.03hr 09min ago</td>\n",
       "      <td>39.61</td>\n",
       "      <td>N</td>\n",
       "      <td>143.50</td>\n",
       "      <td>E</td>\n",
       "      <td>20</td>\n",
       "      <td>mb</td>\n",
       "      <td>4.7</td>\n",
       "      <td>OFF EAST COAST OF HONSHU, JAPAN</td>\n",
       "      <td>2022-03-04 23:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:51:11.13hr 21min ago</td>\n",
       "      <td>19.19</td>\n",
       "      <td>N</td>\n",
       "      <td>155.49</td>\n",
       "      <td>W</td>\n",
       "      <td>31</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.1</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2022-03-04 20:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:50:41.03hr 22min ago</td>\n",
       "      <td>8.03</td>\n",
       "      <td>S</td>\n",
       "      <td>120.56</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>2.8</td>\n",
       "      <td>FLORES REGION, INDONESIA</td>\n",
       "      <td>2022-03-04 20:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:48:43.03hr 24min ago</td>\n",
       "      <td>8.02</td>\n",
       "      <td>S</td>\n",
       "      <td>120.56</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>FLORES REGION, INDONESIA</td>\n",
       "      <td>2022-03-04 20:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:32:18.73hr 40min ago</td>\n",
       "      <td>8.45</td>\n",
       "      <td>S</td>\n",
       "      <td>123.50</td>\n",
       "      <td>E</td>\n",
       "      <td>156</td>\n",
       "      <td>mb</td>\n",
       "      <td>4.3</td>\n",
       "      <td>FLORES REGION, INDONESIA</td>\n",
       "      <td>2022-03-04 22:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:21:26.03hr 51min ago</td>\n",
       "      <td>1.74</td>\n",
       "      <td>N</td>\n",
       "      <td>124.93</td>\n",
       "      <td>E</td>\n",
       "      <td>206</td>\n",
       "      <td>M</td>\n",
       "      <td>3.6</td>\n",
       "      <td>MINAHASA, SULAWESI, INDONESIA</td>\n",
       "      <td>2022-03-04 20:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:16:40.03hr 56min ago</td>\n",
       "      <td>2.80</td>\n",
       "      <td>N</td>\n",
       "      <td>128.57</td>\n",
       "      <td>E</td>\n",
       "      <td>216</td>\n",
       "      <td>M</td>\n",
       "      <td>3.8</td>\n",
       "      <td>HALMAHERA, INDONESIA</td>\n",
       "      <td>2022-03-04 20:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:16:28.73hr 56min ago</td>\n",
       "      <td>18.00</td>\n",
       "      <td>N</td>\n",
       "      <td>67.03</td>\n",
       "      <td>W</td>\n",
       "      <td>16</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>2022-03-04 20:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:14:24.03hr 58min ago</td>\n",
       "      <td>8.11</td>\n",
       "      <td>S</td>\n",
       "      <td>120.52</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>3.2</td>\n",
       "      <td>FLORES REGION, INDONESIA</td>\n",
       "      <td>2022-03-04 20:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:11:04.04hr 02min ago</td>\n",
       "      <td>8.09</td>\n",
       "      <td>S</td>\n",
       "      <td>120.50</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>2.7</td>\n",
       "      <td>FLORES REGION, INDONESIA</td>\n",
       "      <td>2022-03-04 20:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:10:30.44hr 02min ago</td>\n",
       "      <td>19.18</td>\n",
       "      <td>N</td>\n",
       "      <td>155.47</td>\n",
       "      <td>W</td>\n",
       "      <td>31</td>\n",
       "      <td>Ml</td>\n",
       "      <td>2.4</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2022-03-04 20:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:01:15.04hr 11min ago</td>\n",
       "      <td>2.80</td>\n",
       "      <td>N</td>\n",
       "      <td>98.38</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NORTHERN SUMATRA, INDONESIA</td>\n",
       "      <td>2022-03-04 20:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 20:00:00.04hr 13min ago</td>\n",
       "      <td>29.55</td>\n",
       "      <td>S</td>\n",
       "      <td>71.60</td>\n",
       "      <td>W</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>OFFSHORE COQUIMBO, CHILE</td>\n",
       "      <td>2022-03-04 20:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 19:59:04.64hr 14min ago</td>\n",
       "      <td>37.59</td>\n",
       "      <td>N</td>\n",
       "      <td>14.81</td>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.1</td>\n",
       "      <td>SICILY, ITALY</td>\n",
       "      <td>2022-03-04 20:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 19:53:33.04hr 19min ago</td>\n",
       "      <td>22.26</td>\n",
       "      <td>S</td>\n",
       "      <td>70.63</td>\n",
       "      <td>W</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>2.8</td>\n",
       "      <td>OFFSHORE ANTOFAGASTA, CHILE</td>\n",
       "      <td>2022-03-04 20:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 19:39:16.84hr 33min ago</td>\n",
       "      <td>35.49</td>\n",
       "      <td>N</td>\n",
       "      <td>3.68</td>\n",
       "      <td>W</td>\n",
       "      <td>13</td>\n",
       "      <td>ML</td>\n",
       "      <td>1.9</td>\n",
       "      <td>STRAIT OF GIBRALTAR</td>\n",
       "      <td>2022-03-04 20:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 19:20:39.04hr 52min ago</td>\n",
       "      <td>17.97</td>\n",
       "      <td>N</td>\n",
       "      <td>120.68</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>LUZON, PHILIPPINES</td>\n",
       "      <td>2022-03-04 19:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 19:07:39.05hr 05min ago</td>\n",
       "      <td>2.70</td>\n",
       "      <td>S</td>\n",
       "      <td>129.60</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>3.4</td>\n",
       "      <td>SERAM, INDONESIA</td>\n",
       "      <td>2022-03-04 19:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 19:00:59.05hr 12min ago</td>\n",
       "      <td>2.51</td>\n",
       "      <td>S</td>\n",
       "      <td>77.81</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>3.7</td>\n",
       "      <td>PERU-ECUADOR BORDER REGION</td>\n",
       "      <td>2022-03-04 19:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 18:59:55.45hr 13min ago</td>\n",
       "      <td>34.46</td>\n",
       "      <td>S</td>\n",
       "      <td>178.59</td>\n",
       "      <td>E</td>\n",
       "      <td>254</td>\n",
       "      <td>M</td>\n",
       "      <td>3.8</td>\n",
       "      <td>SOUTH OF KERMADEC ISLANDS</td>\n",
       "      <td>2022-03-04 19:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 18:57:43.05hr 15min ago</td>\n",
       "      <td>28.56</td>\n",
       "      <td>N</td>\n",
       "      <td>17.82</td>\n",
       "      <td>W</td>\n",
       "      <td>12</td>\n",
       "      <td>ML</td>\n",
       "      <td>1.6</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "      <td>2022-03-04 20:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 18:49:39.05hr 23min ago</td>\n",
       "      <td>34.82</td>\n",
       "      <td>S</td>\n",
       "      <td>70.36</td>\n",
       "      <td>W</td>\n",
       "      <td>128</td>\n",
       "      <td>M</td>\n",
       "      <td>2.9</td>\n",
       "      <td>LIBERTADOR O'HIGGINS, CHILE</td>\n",
       "      <td>2022-03-04 19:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 18:45:52.15hr 27min ago</td>\n",
       "      <td>35.50</td>\n",
       "      <td>N</td>\n",
       "      <td>3.73</td>\n",
       "      <td>W</td>\n",
       "      <td>12</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.1</td>\n",
       "      <td>STRAIT OF GIBRALTAR</td>\n",
       "      <td>2022-03-04 18:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 18:45:10.05hr 27min ago</td>\n",
       "      <td>42.08</td>\n",
       "      <td>N</td>\n",
       "      <td>8.17</td>\n",
       "      <td>W</td>\n",
       "      <td>24</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.3</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>2022-03-04 18:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04 18:30:27.05hr 42min ago</td>\n",
       "      <td>2.05</td>\n",
       "      <td>S</td>\n",
       "      <td>102.19</td>\n",
       "      <td>E</td>\n",
       "      <td>179</td>\n",
       "      <td>M</td>\n",
       "      <td>3.2</td>\n",
       "      <td>SOUTHERN SUMATRA, INDONESIA</td>\n",
       "      <td>2022-03-04 18:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CitizenResponse                                  \\\n",
       "     12345678910» 12345678910».1 12345678910».2   \n",
       "0              NaN             NaN             NaN   \n",
       "1              NaN             NaN             NaN   \n",
       "2              NaN             NaN             NaN   \n",
       "3              NaN             NaN             NaN   \n",
       "4              NaN             NaN             NaN   \n",
       "5              NaN             NaN             NaN   \n",
       "6                7             NaN              IV   \n",
       "7              NaN             NaN             NaN   \n",
       "8              NaN             NaN             NaN   \n",
       "9              NaN             NaN             NaN   \n",
       "10             NaN             NaN             NaN   \n",
       "11             NaN             NaN             NaN   \n",
       "12             NaN             NaN             NaN   \n",
       "13             NaN             NaN             NaN   \n",
       "14             NaN             NaN             NaN   \n",
       "15             NaN             NaN             NaN   \n",
       "16             NaN             NaN             NaN   \n",
       "17             NaN             NaN             NaN   \n",
       "18             NaN             NaN             NaN   \n",
       "19             NaN             NaN             NaN   \n",
       "20             NaN             NaN             NaN   \n",
       "21             NaN             NaN             NaN   \n",
       "22               6             NaN             III   \n",
       "23             NaN             NaN             NaN   \n",
       "24             NaN             NaN             NaN   \n",
       "25             NaN             NaN             NaN   \n",
       "26             NaN             NaN             NaN   \n",
       "27             NaN             NaN             NaN   \n",
       "28             NaN             NaN             NaN   \n",
       "29             NaN             NaN             NaN   \n",
       "30             NaN             NaN             NaN   \n",
       "31             NaN             NaN             NaN   \n",
       "32             NaN             NaN             NaN   \n",
       "33             NaN             NaN             NaN   \n",
       "34             NaN             NaN             NaN   \n",
       "35             NaN             NaN             NaN   \n",
       "36             NaN             NaN             NaN   \n",
       "37             NaN             NaN             NaN   \n",
       "38             NaN             NaN             NaN   \n",
       "39             NaN             NaN             NaN   \n",
       "40             NaN             NaN             NaN   \n",
       "41             NaN             NaN             NaN   \n",
       "42             NaN             NaN             NaN   \n",
       "43             NaN             NaN             NaN   \n",
       "44             NaN             NaN             NaN   \n",
       "45             NaN             NaN             NaN   \n",
       "46             NaN             NaN             NaN   \n",
       "47             NaN             NaN             NaN   \n",
       "48             NaN             NaN             NaN   \n",
       "49             NaN             NaN             NaN   \n",
       "50             NaN             NaN             NaN   \n",
       "51   12345678910»   12345678910»   12345678910»   \n",
       "52             NaN             NaN             NaN   \n",
       "\n",
       "                       Date & Time UTC Latitude degrees                  \\\n",
       "                         12345678910»    12345678910» 12345678910».1   \n",
       "0       2022-03-04 23:55:25.017min ago            24.65               S   \n",
       "1       2022-03-04 23:52:36.420min ago            37.97               N   \n",
       "2       2022-03-04 23:46:33.026min ago             6.95               S   \n",
       "3       2022-03-04 23:13:42.459min ago            36.35               N   \n",
       "4   2022-03-04 22:54:58.21hr 18min ago            36.61               N   \n",
       "5   2022-03-04 22:39:16.11hr 33min ago            19.19               N   \n",
       "6   2022-03-04 22:32:46.01hr 40min ago            45.40               N   \n",
       "7   2022-03-04 22:31:36.11hr 41min ago            38.77               N   \n",
       "8   2022-03-04 22:31:31.11hr 41min ago            18.02               N   \n",
       "9   2022-03-04 22:29:45.11hr 43min ago            39.63               N   \n",
       "10  2022-03-04 22:28:35.01hr 44min ago            40.48               S   \n",
       "11  2022-03-04 22:28:07.11hr 44min ago            35.74               N   \n",
       "12  2022-03-04 22:26:09.81hr 46min ago            44.64               N   \n",
       "13  2022-03-04 22:20:50.01hr 52min ago             7.82               S   \n",
       "14  2022-03-04 21:59:29.02hr 13min ago            31.44               S   \n",
       "15  2022-03-04 21:58:42.12hr 14min ago            39.20               N   \n",
       "16  2022-03-04 21:53:43.02hr 19min ago             8.05               S   \n",
       "17  2022-03-04 21:43:52.82hr 29min ago            36.53               N   \n",
       "18  2022-03-04 21:40:57.02hr 32min ago            30.43               S   \n",
       "19  2022-03-04 21:38:38.42hr 34min ago            35.50               N   \n",
       "20  2022-03-04 21:25:05.12hr 48min ago            35.60               N   \n",
       "21  2022-03-04 21:19:54.52hr 53min ago            45.80               N   \n",
       "22  2022-03-04 21:17:52.42hr 55min ago            38.64               N   \n",
       "23  2022-03-04 21:09:45.03hr 03min ago            29.54               S   \n",
       "24  2022-03-04 21:05:59.13hr 07min ago            17.96               N   \n",
       "25  2022-03-04 21:03:49.03hr 09min ago            39.61               N   \n",
       "26  2022-03-04 20:51:11.13hr 21min ago            19.19               N   \n",
       "27  2022-03-04 20:50:41.03hr 22min ago             8.03               S   \n",
       "28  2022-03-04 20:48:43.03hr 24min ago             8.02               S   \n",
       "29  2022-03-04 20:32:18.73hr 40min ago             8.45               S   \n",
       "30  2022-03-04 20:21:26.03hr 51min ago             1.74               N   \n",
       "31  2022-03-04 20:16:40.03hr 56min ago             2.80               N   \n",
       "32  2022-03-04 20:16:28.73hr 56min ago            18.00               N   \n",
       "33  2022-03-04 20:14:24.03hr 58min ago             8.11               S   \n",
       "34  2022-03-04 20:11:04.04hr 02min ago             8.09               S   \n",
       "35  2022-03-04 20:10:30.44hr 02min ago            19.18               N   \n",
       "36  2022-03-04 20:01:15.04hr 11min ago             2.80               N   \n",
       "37  2022-03-04 20:00:00.04hr 13min ago            29.55               S   \n",
       "38  2022-03-04 19:59:04.64hr 14min ago            37.59               N   \n",
       "39  2022-03-04 19:53:33.04hr 19min ago            22.26               S   \n",
       "40  2022-03-04 19:39:16.84hr 33min ago            35.49               N   \n",
       "41  2022-03-04 19:20:39.04hr 52min ago            17.97               N   \n",
       "42  2022-03-04 19:07:39.05hr 05min ago             2.70               S   \n",
       "43  2022-03-04 19:00:59.05hr 12min ago             2.51               S   \n",
       "44  2022-03-04 18:59:55.45hr 13min ago            34.46               S   \n",
       "45  2022-03-04 18:57:43.05hr 15min ago            28.56               N   \n",
       "46  2022-03-04 18:49:39.05hr 23min ago            34.82               S   \n",
       "47  2022-03-04 18:45:52.15hr 27min ago            35.50               N   \n",
       "48  2022-03-04 18:45:10.05hr 27min ago            42.08               N   \n",
       "49  2022-03-04 18:30:27.05hr 42min ago             2.05               S   \n",
       "50                                 NaN              NaN             NaN   \n",
       "51                       12345678910»    12345678910»   12345678910»   \n",
       "52                                 NaN              NaN             NaN   \n",
       "\n",
       "   Longitude degrees                       Depth km        Mag [+]  \\\n",
       "       12345678910» 12345678910».1  12345678910»  12345678910»   \n",
       "0              68.87               W            124              M   \n",
       "1             121.90               W              3             Md   \n",
       "2             130.61               E            109             mb   \n",
       "3              14.78               E             13             ML   \n",
       "4             121.07               W              9             Md   \n",
       "5             155.51               W             36             Md   \n",
       "6              16.32               E              8             ML   \n",
       "7             122.72               W              1             Md   \n",
       "8              66.76               W             13             Md   \n",
       "9             143.70               E             10             Mw   \n",
       "10             72.14               W              9              M   \n",
       "11              3.47               W              2             ML   \n",
       "12              7.42               E              2             ML   \n",
       "13            118.63               E             28              M   \n",
       "14             69.17               W            113              M   \n",
       "15             16.69               E             18             ML   \n",
       "16            120.54               E             10              M   \n",
       "17            121.11               W              6             Md   \n",
       "18             71.83               W             30              M   \n",
       "19              3.67               W              2             ML   \n",
       "20            120.27               W             12             Md   \n",
       "21              9.10               E             39             ML   \n",
       "22             15.62               E            174             mb   \n",
       "23             71.60               W             24              M   \n",
       "24             66.85               W             13             Md   \n",
       "25            143.50               E             20             mb   \n",
       "26            155.49               W             31             Md   \n",
       "27            120.56               E             10              M   \n",
       "28            120.56               E             10              M   \n",
       "29            123.50               E            156             mb   \n",
       "30            124.93               E            206              M   \n",
       "31            128.57               E            216              M   \n",
       "32             67.03               W             16             Md   \n",
       "33            120.52               E             10              M   \n",
       "34            120.50               E             10              M   \n",
       "35            155.47               W             31             Ml   \n",
       "36             98.38               E             10              M   \n",
       "37             71.60               W             25              M   \n",
       "38             14.81               E              4             ML   \n",
       "39             70.63               W             20              M   \n",
       "40              3.68               W             13             ML   \n",
       "41            120.68               E              2              M   \n",
       "42            129.60               E             10              M   \n",
       "43             77.81               W              2              M   \n",
       "44            178.59               E            254              M   \n",
       "45             17.82               W             12             ML   \n",
       "46             70.36               W            128              M   \n",
       "47              3.73               W             12             ML   \n",
       "48              8.17               W             24             ML   \n",
       "49            102.19               E            179              M   \n",
       "50               NaN             NaN            NaN            NaN   \n",
       "51     12345678910»   12345678910»  12345678910»  12345678910»   \n",
       "52               NaN             NaN            NaN            NaN   \n",
       "\n",
       "   Region name [+]                  Last update [-] Unnamed: 12_level_0  \n",
       "     12345678910»                    12345678910»       12345678910»  \n",
       "0              2.7               ANTOFAGASTA, CHILE    2022-03-05 00:03  \n",
       "1              2.0   SAN FRANCISCO BAY AREA, CALIF.    2022-03-04 23:54  \n",
       "2              4.7                        BANDA SEA    2022-03-05 00:07  \n",
       "3              2.4                    SICILY, ITALY    2022-03-04 23:25  \n",
       "4              2.0               CENTRAL CALIFORNIA    2022-03-04 22:56  \n",
       "5              2.5         ISLAND OF HAWAII, HAWAII    2022-03-04 22:42  \n",
       "6              2.1                          CROATIA    2022-03-04 22:35  \n",
       "7              2.0              NORTHERN CALIFORNIA    2022-03-04 22:33  \n",
       "8              2.4                      PUERTO RICO    2022-03-04 22:46  \n",
       "9              5.1  OFF EAST COAST OF HONSHU, JAPAN    2022-03-04 23:38  \n",
       "10             2.6                 LOS LAGOS, CHILE    2022-03-04 22:42  \n",
       "11             2.2              STRAIT OF GIBRALTAR    2022-03-04 22:38  \n",
       "12             2.5                   NORTHERN ITALY    2022-03-04 22:33  \n",
       "13             3.8                       FLORES SEA    2022-03-04 22:30  \n",
       "14             4.1              SAN JUAN, ARGENTINA    2022-03-04 22:05  \n",
       "15             2.5                   SOUTHERN ITALY    2022-03-04 22:10  \n",
       "16             3.9         FLORES REGION, INDONESIA    2022-03-04 22:00  \n",
       "17             2.1               CENTRAL CALIFORNIA    2022-03-04 21:45  \n",
       "18             3.7         OFFSHORE COQUIMBO, CHILE    2022-03-04 22:12  \n",
       "19             2.3              STRAIT OF GIBRALTAR    2022-03-04 22:29  \n",
       "20             2.3               CENTRAL CALIFORNIA    2022-03-04 21:26  \n",
       "21             2.1                   NORTHERN ITALY    2022-03-04 21:26  \n",
       "22             4.4                    SICILY, ITALY    2022-03-04 22:00  \n",
       "23             2.7         OFFSHORE COQUIMBO, CHILE    2022-03-04 21:21  \n",
       "24             2.4                      PUERTO RICO    2022-03-04 21:24  \n",
       "25             4.7  OFF EAST COAST OF HONSHU, JAPAN    2022-03-04 23:03  \n",
       "26             2.1         ISLAND OF HAWAII, HAWAII    2022-03-04 20:54  \n",
       "27             2.8         FLORES REGION, INDONESIA    2022-03-04 20:55  \n",
       "28             3.0         FLORES REGION, INDONESIA    2022-03-04 20:55  \n",
       "29             4.3         FLORES REGION, INDONESIA    2022-03-04 22:45  \n",
       "30             3.6    MINAHASA, SULAWESI, INDONESIA    2022-03-04 20:30  \n",
       "31             3.8             HALMAHERA, INDONESIA    2022-03-04 20:25  \n",
       "32             2.4                      PUERTO RICO    2022-03-04 20:27  \n",
       "33             3.2         FLORES REGION, INDONESIA    2022-03-04 20:30  \n",
       "34             2.7         FLORES REGION, INDONESIA    2022-03-04 20:30  \n",
       "35             2.4         ISLAND OF HAWAII, HAWAII    2022-03-04 20:16  \n",
       "36             2.5      NORTHERN SUMATRA, INDONESIA    2022-03-04 20:15  \n",
       "37             3.0         OFFSHORE COQUIMBO, CHILE    2022-03-04 20:11  \n",
       "38             2.1                    SICILY, ITALY    2022-03-04 20:08  \n",
       "39             2.8      OFFSHORE ANTOFAGASTA, CHILE    2022-03-04 20:06  \n",
       "40             1.9              STRAIT OF GIBRALTAR    2022-03-04 20:38  \n",
       "41             3.0               LUZON, PHILIPPINES    2022-03-04 19:30  \n",
       "42             3.4                 SERAM, INDONESIA    2022-03-04 19:25  \n",
       "43             3.7       PERU-ECUADOR BORDER REGION    2022-03-04 19:10  \n",
       "44             3.8        SOUTH OF KERMADEC ISLANDS    2022-03-04 19:10  \n",
       "45             1.6     CANARY ISLANDS, SPAIN REGION    2022-03-04 20:46  \n",
       "46             2.9      LIBERTADOR O'HIGGINS, CHILE    2022-03-04 19:08  \n",
       "47             2.1              STRAIT OF GIBRALTAR    2022-03-04 18:55  \n",
       "48             2.3                            SPAIN    2022-03-04 18:50  \n",
       "49             3.2      SOUTHERN SUMATRA, INDONESIA    2022-03-04 18:45  \n",
       "50             NaN                              NaN                 NaN  \n",
       "51   12345678910»                    12345678910»       12345678910»  \n",
       "52             NaN                              NaN                 NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the date, days, title, city, country of next 25 hackathon events as a Pandas dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.eventbrite.com.mx/d/online/hackathon/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FinTech Virtual & Hybrid Hackathon 2022',\n",
       " 'FinTech Virtual & Hybrid Hackathon 2022',\n",
       " 'GovTech Virtual & Hybrid Hackathon 2022',\n",
       " 'GovTech Virtual & Hybrid Hackathon 2022',\n",
       " 'NEAR Hackathon Finale and Prizegiving',\n",
       " 'NEAR Hackathon Finale and Prizegiving',\n",
       " 'Students in Mind Hackathon 2022',\n",
       " 'Students in Mind Hackathon 2022',\n",
       " 'HealthTech Virtual & Hybrid Hackathon 2022',\n",
       " 'HealthTech Virtual & Hybrid Hackathon 2022',\n",
       " 'All-Women Virtual Hackathon - Break the Bias. Build Leaders.',\n",
       " 'All-Women Virtual Hackathon - Break the Bias. Build Leaders.',\n",
       " 'RecruitaTH0n (Grads & Interns) Virtual Hackathon 2022',\n",
       " 'RecruitaTH0n (Grads & Interns) Virtual Hackathon 2022',\n",
       " 'eGaming Virtual & Hybrid Hackathon  2022',\n",
       " 'eGaming Virtual & Hybrid Hackathon  2022',\n",
       " 'SportsTech Virtual & Hybrid Hackathon 2022',\n",
       " 'SportsTech Virtual & Hybrid Hackathon 2022',\n",
       " 'StarkNet Hackathon Finale and Prizegiving',\n",
       " 'StarkNet Hackathon Finale and Prizegiving',\n",
       " 'NLP & IoT Hackathon - powered by Waylay',\n",
       " 'NLP & IoT Hackathon - powered by Waylay',\n",
       " '#BISONHACKS 2022 8th Annual Howard University Hackathon',\n",
       " '#BISONHACKS 2022 8th Annual Howard University Hackathon',\n",
       " 'INFO SESSION | מפגש מידע | SPRING 2022 INTERNATIONAL HACKATHON',\n",
       " 'INFO SESSION | מפגש מידע | SPRING 2022 INTERNATIONAL HACKATHON',\n",
       " 'Web 3.0 Virtual Hackathon - Re-imagining the Creator Economy',\n",
       " 'Web 3.0 Virtual Hackathon - Re-imagining the Creator Economy',\n",
       " 'RecruitaTH0n (Green Jobs) Virtual & Hybrid Hackathon 2022',\n",
       " 'RecruitaTH0n (Green Jobs) Virtual & Hybrid Hackathon 2022',\n",
       " 'LGBTQIA+ (Inclusion & Diversity) Virtual & Hybrid Hackathon 2022',\n",
       " 'LGBTQIA+ (Inclusion & Diversity) Virtual & Hybrid Hackathon 2022',\n",
       " 'Hack for Good: The Mental Health Project Online Hackathon',\n",
       " 'Hack for Good: The Mental Health Project Online Hackathon',\n",
       " 'Young Climathon Virtual & Hybrid Hackathon 2022',\n",
       " 'Young Climathon Virtual & Hybrid Hackathon 2022',\n",
       " 'Blockchain & AI Virtual & Hybrid Hackathon 2022',\n",
       " 'Blockchain & AI Virtual & Hybrid Hackathon 2022',\n",
       " 'How to organize a Hackathon?',\n",
       " 'How to organize a Hackathon?']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "response = requests.get(url)\n",
    "http = urllib.request.Request(url)\n",
    "http\n",
    "response\n",
    "html = response. content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "titulo = soup.select('div[class=\"eds-event-card__formatted-name--is-clamped eds-event-card__formatted-name--is-clamped-three eds-text-weight--heavy\"]')\n",
    "movie_titulo = [element.text for element in titulo]\n",
    "clean_titulo = [text.strip().replace('\\n', '') for text in movie_titulo]\n",
    "\n",
    "clean_titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fri, Apr 22, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Apr 22, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Apr 8, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Apr 8, 2022 7:00 PM BST (+01:00)',\n",
       " 'Tue, Mar 29, 2022 5:30 PM BST (+01:00)',\n",
       " 'Tue, Mar 29, 2022 5:30 PM BST (+01:00)',\n",
       " 'Sat, Mar 12, 2022 10:00 AM EST (-05:00)',\n",
       " 'Sat, Mar 12, 2022 10:00 AM EST (-05:00)',\n",
       " 'Fri, Jun 10, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Jun 10, 2022 7:00 PM BST (+01:00)',\n",
       " 'Tue, Mar 22, 2022 10:00 AM PDT (-07:00)',\n",
       " 'Tue, Mar 22, 2022 10:00 AM PDT (-07:00)',\n",
       " 'Fri, May 27, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, May 27, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Aug 19, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Aug 19, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Jul 15, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Jul 15, 2022 7:00 PM BST (+01:00)',\n",
       " 'Mon, Apr 11, 2022 5:30 PM BST (+01:00)',\n",
       " 'Mon, Apr 11, 2022 5:30 PM BST (+01:00)',\n",
       " 'Wed, Mar 23, 2022 5:30 PM CET (+01:00)',\n",
       " 'Wed, Mar 23, 2022 5:30 PM CET (+01:00)',\n",
       " 'Fri, Mar 18, 2022 10:00 AM EDT (-04:00)',\n",
       " 'Fri, Mar 18, 2022 10:00 AM EDT (-04:00)',\n",
       " 'Sun, Mar 13, 2022 7:00 PM IST (+02:00)',\n",
       " 'Sun, Mar 13, 2022 7:00 PM IST (+02:00)',\n",
       " 'Sun, Apr 24, 2022 5:00 PM UTC (+00:00)',\n",
       " 'Sun, Apr 24, 2022 5:00 PM UTC (+00:00)',\n",
       " 'Fri, Oct 21, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Oct 21, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Jun 24, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Jun 24, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Mar 25, 2022 2:00 PM EDT (-04:00)',\n",
       " 'Fri, Mar 25, 2022 2:00 PM EDT (-04:00)',\n",
       " 'Fri, Oct 28, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Oct 28, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Nov 11, 2022 7:00 PM GMT (+00:00)',\n",
       " 'Fri, Nov 11, 2022 7:00 PM GMT (+00:00)',\n",
       " 'Tue, Apr 5, 2022 7:00 PM EDT (-04:00) + 2 more events',\n",
       " 'Tue, Apr 5, 2022 7:00 PM EDT (-04:00) + 2 more events']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fechas = soup.select('div[class=\"eds-event-card-content__sub-title eds-text-color--ui-orange eds-l-pad-bot-1 eds-l-pad-top-2 eds-text-weight--heavy eds-text-bm\"]')\n",
    "fechas_titulo = [element.text for element in fechas]\n",
    "clean_fechas = [text.strip().replace('\\n', '') for text in fechas_titulo]\n",
    "clean_fechas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English 6,383,000 articles',\n",
       " '日本語 1,292,000 記事',\n",
       " 'Русский 1,756,000 статей',\n",
       " 'Deutsch 2,617,000 Artikel',\n",
       " 'Español 1,717,000 artículos',\n",
       " 'Français 2,362,000 articles',\n",
       " '中文 1,231,000 條目',\n",
       " 'Italiano 1,718,000 voci',\n",
       " 'Polski 1,490,000 haseł',\n",
       " 'Português 1,074,000 artigos']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "url = 'https://www.wikipedia.org/'\n",
    "response = requests.get(url)\n",
    "html = response.content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "titulo = soup.select('a[class=\"link-box\"]')\n",
    "movie_titulo = [element.text for element in titulo]\n",
    "clean_titulo = [text.strip().replace(u'\\xa0', u',').replace('+', '').replace('\\n', ' ') for text in movie_titulo]\n",
    "clean_titulo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6,383,000+',\n",
       " '1,292,000+',\n",
       " '1,756,000+',\n",
       " '2,617,000+',\n",
       " '1,717,000+',\n",
       " '2,362,000+',\n",
       " '1,231,000+',\n",
       " '1,718,000+',\n",
       " '1,490,000+',\n",
       " '1,074,000+',\n",
       " '1,000,000+',\n",
       " '100,000+',\n",
       " '10,000+',\n",
       " '1,000+',\n",
       " '100+']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.wikipedia.org/'\n",
    "response = requests.get(url)\n",
    "html = response.content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "titulo = soup.select('bdi[dir=\"ltr\"]')\n",
    "movie_titulo = [element.text for element in titulo]\n",
    "clean_titulo = [text.strip().replace(u'\\xa0', u',') for text in movie_titulo]\n",
    "clean_titulo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code \n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('h3 a.govuk-link')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "html = requests.get(url).content\n",
    "table = pd.read_html(html, match='Languages with at least 10 million first-language speakers')\n",
    "table[0].head(10)\n",
    "#wikitable sortable jquery-tablesorter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
