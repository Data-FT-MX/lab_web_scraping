{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scrapy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\WMMIRA~1\\AppData\\Local\\Temp/ipykernel_7080/2664468086.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scrapy'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from lxml import html\n",
    "from lxml.html import fromstring\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "import re\n",
    "import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "response = requests.get(url)\n",
    "html = response.content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.select('div h1.h3.lh-condensed')\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_name = [text.strip() for text in name]\n",
    "clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "responses = requests.get(url)\n",
    "html = responses.content\n",
    "soups = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = soups.select('div h1.h3.lh-condensed')\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [element.text for element in titles]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_names = [text.strip().replace('\\n','') for text in names]\n",
    "clean_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "responses = requests.get(url)\n",
    "html = responses.content\n",
    "soups = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = soups.select('div h1.h3.lh-condensed')\n",
    "names = [element.text for element in titles]\n",
    "clean_names = [text.strip().replace('\\n','') for text in names]\n",
    "clean_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "respon = requests.get(urls)\n",
    "htmls = respon.content\n",
    "htmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sou = BeautifulSoup(htmls, 'lxml')\n",
    "tags_image = sou.select('img')\n",
    "tags_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_src = [element['src'] for element in tags_image]\n",
    "image_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "r = requests.get(urli)\n",
    "s = BeautifulSoup(h,'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = s.find_all('a', href=True)\n",
    "[element['href'] for element in links]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['All titles in the format selected compressed into a zip archive.',\n",
       " '',\n",
       " 'Title 1 - General Provisions ٭',\n",
       " 'Title 2 - The Congress',\n",
       " 'Title 3 - The President ٭',\n",
       " 'Title 4 - Flag and Seal, Seat of Government, and the States ٭',\n",
       " 'Title 5 - Government Organization and Employees ٭',\n",
       " 'Title 6 - Domestic Security',\n",
       " 'Title 7 - Agriculture',\n",
       " 'Title 8 - Aliens and Nationality',\n",
       " 'Title 9 - Arbitration ٭',\n",
       " 'Title 10 - Armed Forces ٭',\n",
       " 'Title 11 - Bankruptcy ٭',\n",
       " 'Title 12 - Banks and Banking',\n",
       " 'Title 13 - Census ٭',\n",
       " 'Title 14 - Coast Guard ٭',\n",
       " 'Title 15 - Commerce and Trade',\n",
       " 'Title 16 - Conservation',\n",
       " 'Title 17 - Copyrights ٭',\n",
       " 'Title 18 - Crimes and Criminal Procedure ٭',\n",
       " 'Title 19 - Customs Duties',\n",
       " 'Title 20 - Education',\n",
       " 'Title 21 - Food and Drugs',\n",
       " 'Title 22 - Foreign Relations and Intercourse',\n",
       " 'Title 23 - Highways ٭',\n",
       " 'Title 24 - Hospitals and Asylums',\n",
       " 'Title 25 - Indians',\n",
       " 'Title 26 - Internal Revenue Code',\n",
       " 'Title 27 - Intoxicating Liquors',\n",
       " 'Title 28 - Judiciary and Judicial Procedure ٭',\n",
       " 'Title 29 - Labor',\n",
       " 'Title 30 - Mineral Lands and Mining',\n",
       " 'Title 31 - Money and Finance ٭',\n",
       " 'Title 32 - National Guard ٭',\n",
       " 'Title 33 - Navigation and Navigable Waters',\n",
       " 'Title 34 - Crime Control and Law Enforcement',\n",
       " 'Title 35 - Patents ٭',\n",
       " 'Title 36 - Patriotic and National Observances, Ceremonies, and Organizations ٭',\n",
       " 'Title 37 - Pay and Allowances of the Uniformed Services ٭',\n",
       " \"Title 38 - Veterans' Benefits ٭\",\n",
       " 'Title 39 - Postal Service ٭',\n",
       " 'Title 41 - Public Contracts ٭',\n",
       " 'Title 42 - The Public Health and Welfare',\n",
       " 'Title 43 - Public Lands',\n",
       " 'Title 44 - Public Printing and Documents ٭',\n",
       " 'Title 45 - Railroads',\n",
       " 'Title 46 - Shipping ٭',\n",
       " 'Title 47 - Telecommunications',\n",
       " 'Title 48 - Territories and Insular Possessions',\n",
       " 'Title 49 - Transportation ٭',\n",
       " 'Title 50 - War and National Defense',\n",
       " 'Title 51 - National and Commercial Space Programs ٭',\n",
       " 'Title 52 - Voting and Elections',\n",
       " 'Title 53 [Reserved]',\n",
       " 'Title 54 - National Park Service and Related Programs ٭']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup.select('div.usctitle')\n",
    "titles_text = [element.text.strip() for element in title]\n",
    "titles_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code \n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EUGENE PALMER',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'JASON DEREK BROWN',\n",
       " 'ALEXIS FLORES',\n",
       " 'JOSE RODOLFO VILLARREAL-HERNANDEZ',\n",
       " 'OCTAVIANO JUAREZ-CORRO',\n",
       " 'RAFAEL CARO-QUINTERO',\n",
       " 'YULAN ADONAY ARCHAGA CARIAS']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_wanted = soup.select('h3.title')\n",
    "most_wanted_names = [name.text.strip() for name in most_wanted]\n",
    "most_wanted_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_html(html)\n",
    "len(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">CitizenResponse</th>\n",
       "      <th>Date &amp; Time UTC</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Latitude degrees</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Longitude degrees</th>\n",
       "      <th>Depth km</th>\n",
       "      <th>Mag [+]</th>\n",
       "      <th>Region name [+]</th>\n",
       "      <th>Last update [-]</th>\n",
       "      <th>Unnamed: 12_level_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910».1</th>\n",
       "      <th>12345678910».2</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910».1</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910».1</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910»</th>\n",
       "      <th>12345678910»</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>III</td>\n",
       "      <td>2022-01-24 22:04:45.015min ago</td>\n",
       "      <td>34.89</td>\n",
       "      <td>N</td>\n",
       "      <td>25.25</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>ML</td>\n",
       "      <td>3.5</td>\n",
       "      <td>CRETE, GREECE</td>\n",
       "      <td>2022-01-24 22:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 22:03:35.016min ago</td>\n",
       "      <td>2.82</td>\n",
       "      <td>S</td>\n",
       "      <td>129.42</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>4.4</td>\n",
       "      <td>SERAM, INDONESIA</td>\n",
       "      <td>2022-01-24 22:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IV</td>\n",
       "      <td>2022-01-24 22:00:49.919min ago</td>\n",
       "      <td>46.01</td>\n",
       "      <td>N</td>\n",
       "      <td>15.13</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.5</td>\n",
       "      <td>SLOVENIA</td>\n",
       "      <td>2022-01-24 22:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2022-01-24 21:58:06.422min ago</td>\n",
       "      <td>19.23</td>\n",
       "      <td>N</td>\n",
       "      <td>155.39</td>\n",
       "      <td>W</td>\n",
       "      <td>33</td>\n",
       "      <td>Ml</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2022-01-24 22:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 21:50:10.930min ago</td>\n",
       "      <td>33.27</td>\n",
       "      <td>S</td>\n",
       "      <td>117.21</td>\n",
       "      <td>E</td>\n",
       "      <td>7</td>\n",
       "      <td>ML</td>\n",
       "      <td>3.6</td>\n",
       "      <td>WESTERN AUSTRALIA</td>\n",
       "      <td>2022-01-24 22:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 21:43:39.936min ago</td>\n",
       "      <td>37.09</td>\n",
       "      <td>N</td>\n",
       "      <td>120.99</td>\n",
       "      <td>W</td>\n",
       "      <td>6</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.2</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "      <td>2022-01-24 21:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 21:39:00.441min ago</td>\n",
       "      <td>28.55</td>\n",
       "      <td>N</td>\n",
       "      <td>17.85</td>\n",
       "      <td>W</td>\n",
       "      <td>11</td>\n",
       "      <td>ML</td>\n",
       "      <td>1.6</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "      <td>2022-01-24 21:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IV</td>\n",
       "      <td>2022-01-24 21:24:47.755min ago</td>\n",
       "      <td>33.29</td>\n",
       "      <td>S</td>\n",
       "      <td>117.00</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>mb</td>\n",
       "      <td>4.8</td>\n",
       "      <td>WESTERN AUSTRALIA</td>\n",
       "      <td>2022-01-24 22:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 21:21:22.658min ago</td>\n",
       "      <td>35.42</td>\n",
       "      <td>N</td>\n",
       "      <td>32.23</td>\n",
       "      <td>E</td>\n",
       "      <td>5</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.6</td>\n",
       "      <td>CYPRUS REGION</td>\n",
       "      <td>2022-01-24 21:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 21:17:43.81hr 02min ago</td>\n",
       "      <td>58.35</td>\n",
       "      <td>S</td>\n",
       "      <td>25.30</td>\n",
       "      <td>W</td>\n",
       "      <td>33</td>\n",
       "      <td>mb</td>\n",
       "      <td>5.1</td>\n",
       "      <td>SOUTH SANDWICH ISLANDS REGION</td>\n",
       "      <td>2022-01-24 21:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 21:16:40.81hr 03min ago</td>\n",
       "      <td>19.36</td>\n",
       "      <td>S</td>\n",
       "      <td>173.35</td>\n",
       "      <td>W</td>\n",
       "      <td>114</td>\n",
       "      <td>mb</td>\n",
       "      <td>5.0</td>\n",
       "      <td>TONGA</td>\n",
       "      <td>2022-01-24 21:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IV</td>\n",
       "      <td>2022-01-24 21:14:13.01hr 05min ago</td>\n",
       "      <td>8.84</td>\n",
       "      <td>S</td>\n",
       "      <td>116.15</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>4.7</td>\n",
       "      <td>LOMBOK REGION, INDONESIA</td>\n",
       "      <td>2022-01-24 21:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 21:12:32.41hr 07min ago</td>\n",
       "      <td>38.47</td>\n",
       "      <td>N</td>\n",
       "      <td>39.23</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.8</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "      <td>2022-01-24 21:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 21:09:22.11hr 10min ago</td>\n",
       "      <td>37.84</td>\n",
       "      <td>N</td>\n",
       "      <td>14.67</td>\n",
       "      <td>E</td>\n",
       "      <td>34</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.1</td>\n",
       "      <td>SICILY, ITALY</td>\n",
       "      <td>2022-01-24 21:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 21:08:51.71hr 11min ago</td>\n",
       "      <td>17.97</td>\n",
       "      <td>N</td>\n",
       "      <td>66.51</td>\n",
       "      <td>W</td>\n",
       "      <td>13</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.5</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>2022-01-24 21:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 21:07:22.41hr 12min ago</td>\n",
       "      <td>46.20</td>\n",
       "      <td>N</td>\n",
       "      <td>7.30</td>\n",
       "      <td>E</td>\n",
       "      <td>8</td>\n",
       "      <td>ML</td>\n",
       "      <td>1.3</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>2022-01-24 21:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 21:02:28.11hr 17min ago</td>\n",
       "      <td>19.23</td>\n",
       "      <td>N</td>\n",
       "      <td>155.39</td>\n",
       "      <td>W</td>\n",
       "      <td>32</td>\n",
       "      <td>Md</td>\n",
       "      <td>2.2</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2022-01-24 21:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 20:57:56.51hr 22min ago</td>\n",
       "      <td>19.22</td>\n",
       "      <td>N</td>\n",
       "      <td>155.42</td>\n",
       "      <td>W</td>\n",
       "      <td>33</td>\n",
       "      <td>Ml</td>\n",
       "      <td>2.3</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2022-01-24 21:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 20:55:16.71hr 24min ago</td>\n",
       "      <td>18.51</td>\n",
       "      <td>N</td>\n",
       "      <td>73.33</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>4.2</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2022-01-24 21:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 20:54:55.01hr 25min ago</td>\n",
       "      <td>19.19</td>\n",
       "      <td>N</td>\n",
       "      <td>68.86</td>\n",
       "      <td>W</td>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "      <td>2.5</td>\n",
       "      <td>DOMINICAN REPUBLIC REGION</td>\n",
       "      <td>2022-01-24 21:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 20:54:12.81hr 25min ago</td>\n",
       "      <td>18.51</td>\n",
       "      <td>N</td>\n",
       "      <td>73.31</td>\n",
       "      <td>W</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2022-01-24 21:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 20:52:59.41hr 27min ago</td>\n",
       "      <td>19.81</td>\n",
       "      <td>N</td>\n",
       "      <td>72.99</td>\n",
       "      <td>W</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>4.3</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2022-01-24 21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 20:39:15.01hr 40min ago</td>\n",
       "      <td>9.17</td>\n",
       "      <td>N</td>\n",
       "      <td>82.09</td>\n",
       "      <td>W</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>3.6</td>\n",
       "      <td>PANAMA-COSTA RICA BORDER REGION</td>\n",
       "      <td>2022-01-24 20:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 20:29:31.21hr 50min ago</td>\n",
       "      <td>42.83</td>\n",
       "      <td>N</td>\n",
       "      <td>1.33</td>\n",
       "      <td>W</td>\n",
       "      <td>10</td>\n",
       "      <td>ML</td>\n",
       "      <td>1.8</td>\n",
       "      <td>PYRENEES</td>\n",
       "      <td>2022-01-24 20:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 20:26:58.71hr 53min ago</td>\n",
       "      <td>18.52</td>\n",
       "      <td>N</td>\n",
       "      <td>73.33</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>3.1</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2022-01-24 20:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2022-01-24 20:25:45.01hr 54min ago</td>\n",
       "      <td>37.59</td>\n",
       "      <td>S</td>\n",
       "      <td>179.66</td>\n",
       "      <td>W</td>\n",
       "      <td>20</td>\n",
       "      <td>mb</td>\n",
       "      <td>5.2</td>\n",
       "      <td>EAST OF NORTH ISLAND, N.Z.</td>\n",
       "      <td>2022-01-24 21:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 20:19:47.02hr 00min ago</td>\n",
       "      <td>21.71</td>\n",
       "      <td>S</td>\n",
       "      <td>69.76</td>\n",
       "      <td>W</td>\n",
       "      <td>85</td>\n",
       "      <td>M</td>\n",
       "      <td>2.5</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "      <td>2022-01-24 20:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 20:01:44.92hr 18min ago</td>\n",
       "      <td>18.51</td>\n",
       "      <td>N</td>\n",
       "      <td>73.29</td>\n",
       "      <td>W</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>4.6</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2022-01-24 20:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2022-01-24 19:46:43.82hr 33min ago</td>\n",
       "      <td>38.45</td>\n",
       "      <td>N</td>\n",
       "      <td>39.22</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>ML</td>\n",
       "      <td>3.0</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "      <td>2022-01-24 20:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 19:43:12.02hr 37min ago</td>\n",
       "      <td>16.60</td>\n",
       "      <td>N</td>\n",
       "      <td>94.46</td>\n",
       "      <td>W</td>\n",
       "      <td>103</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OAXACA, MEXICO</td>\n",
       "      <td>2022-01-24 20:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 19:41:33.52hr 38min ago</td>\n",
       "      <td>19.10</td>\n",
       "      <td>N</td>\n",
       "      <td>64.64</td>\n",
       "      <td>W</td>\n",
       "      <td>9</td>\n",
       "      <td>Md</td>\n",
       "      <td>3.3</td>\n",
       "      <td>VIRGIN ISLANDS REGION</td>\n",
       "      <td>2022-01-24 20:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2022-01-24 19:39:00.02hr 41min ago</td>\n",
       "      <td>29.79</td>\n",
       "      <td>N</td>\n",
       "      <td>80.35</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NEPAL-INDIA BORDER REGION</td>\n",
       "      <td>2022-01-24 19:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 19:37:56.12hr 42min ago</td>\n",
       "      <td>31.68</td>\n",
       "      <td>N</td>\n",
       "      <td>104.44</td>\n",
       "      <td>W</td>\n",
       "      <td>9</td>\n",
       "      <td>ML</td>\n",
       "      <td>3.2</td>\n",
       "      <td>WESTERN TEXAS</td>\n",
       "      <td>2022-01-24 20:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 19:36:03.42hr 44min ago</td>\n",
       "      <td>35.47</td>\n",
       "      <td>N</td>\n",
       "      <td>3.67</td>\n",
       "      <td>W</td>\n",
       "      <td>22</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STRAIT OF GIBRALTAR</td>\n",
       "      <td>2022-01-24 20:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 19:26:26.52hr 53min ago</td>\n",
       "      <td>18.17</td>\n",
       "      <td>N</td>\n",
       "      <td>72.36</td>\n",
       "      <td>W</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>3.2</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2022-01-24 19:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 19:25:08.62hr 55min ago</td>\n",
       "      <td>33.36</td>\n",
       "      <td>N</td>\n",
       "      <td>117.91</td>\n",
       "      <td>W</td>\n",
       "      <td>10</td>\n",
       "      <td>Ml</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GULF OF SANTA CATALINA, CALIF.</td>\n",
       "      <td>2022-01-24 19:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 19:23:39.92hr 56min ago</td>\n",
       "      <td>3.63</td>\n",
       "      <td>N</td>\n",
       "      <td>126.70</td>\n",
       "      <td>E</td>\n",
       "      <td>58</td>\n",
       "      <td>mb</td>\n",
       "      <td>4.9</td>\n",
       "      <td>KEPULAUAN TALAUD, INDONESIA</td>\n",
       "      <td>2022-01-24 20:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 19:10:20.03hr 09min ago</td>\n",
       "      <td>37.19</td>\n",
       "      <td>N</td>\n",
       "      <td>30.93</td>\n",
       "      <td>E</td>\n",
       "      <td>104</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.5</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "      <td>2022-01-24 19:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 19:09:37.13hr 10min ago</td>\n",
       "      <td>42.65</td>\n",
       "      <td>N</td>\n",
       "      <td>45.35</td>\n",
       "      <td>E</td>\n",
       "      <td>5</td>\n",
       "      <td>mb</td>\n",
       "      <td>3.8</td>\n",
       "      <td>CAUCASUS REGION, RUSSIA</td>\n",
       "      <td>2022-01-24 20:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 18:58:11.73hr 22min ago</td>\n",
       "      <td>33.33</td>\n",
       "      <td>S</td>\n",
       "      <td>117.00</td>\n",
       "      <td>E</td>\n",
       "      <td>3</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.6</td>\n",
       "      <td>WESTERN AUSTRALIA</td>\n",
       "      <td>2022-01-24 19:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 18:53:17.93hr 26min ago</td>\n",
       "      <td>35.71</td>\n",
       "      <td>S</td>\n",
       "      <td>179.41</td>\n",
       "      <td>E</td>\n",
       "      <td>292</td>\n",
       "      <td>M</td>\n",
       "      <td>3.6</td>\n",
       "      <td>OFF E. COAST OF N. ISLAND, N.Z.</td>\n",
       "      <td>2022-01-24 19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 18:50:20.63hr 29min ago</td>\n",
       "      <td>18.47</td>\n",
       "      <td>N</td>\n",
       "      <td>73.28</td>\n",
       "      <td>W</td>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>3.3</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2022-01-24 18:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 18:48:34.03hr 31min ago</td>\n",
       "      <td>42.83</td>\n",
       "      <td>N</td>\n",
       "      <td>1.32</td>\n",
       "      <td>W</td>\n",
       "      <td>9</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.3</td>\n",
       "      <td>PYRENEES</td>\n",
       "      <td>2022-01-24 19:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 18:40:43.13hr 39min ago</td>\n",
       "      <td>18.51</td>\n",
       "      <td>N</td>\n",
       "      <td>73.32</td>\n",
       "      <td>W</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>3.7</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2022-01-24 18:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 18:40:23.03hr 39min ago</td>\n",
       "      <td>20.11</td>\n",
       "      <td>S</td>\n",
       "      <td>69.15</td>\n",
       "      <td>W</td>\n",
       "      <td>94</td>\n",
       "      <td>M</td>\n",
       "      <td>2.8</td>\n",
       "      <td>TARAPACA, CHILE</td>\n",
       "      <td>2022-01-24 18:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 18:38:16.13hr 41min ago</td>\n",
       "      <td>18.50</td>\n",
       "      <td>N</td>\n",
       "      <td>73.27</td>\n",
       "      <td>W</td>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>3.6</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2022-01-24 18:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 18:32:23.23hr 47min ago</td>\n",
       "      <td>18.50</td>\n",
       "      <td>N</td>\n",
       "      <td>73.30</td>\n",
       "      <td>W</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>3.6</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2022-01-24 18:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 18:29:02.13hr 51min ago</td>\n",
       "      <td>45.49</td>\n",
       "      <td>N</td>\n",
       "      <td>10.25</td>\n",
       "      <td>E</td>\n",
       "      <td>8</td>\n",
       "      <td>ML</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NORTHERN ITALY</td>\n",
       "      <td>2022-01-24 18:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 18:23:11.83hr 57min ago</td>\n",
       "      <td>63.30</td>\n",
       "      <td>N</td>\n",
       "      <td>151.30</td>\n",
       "      <td>W</td>\n",
       "      <td>12</td>\n",
       "      <td>ML</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CENTRAL ALASKA</td>\n",
       "      <td>2022-01-24 19:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-24 18:16:16.34hr 03min ago</td>\n",
       "      <td>18.45</td>\n",
       "      <td>N</td>\n",
       "      <td>73.30</td>\n",
       "      <td>W</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>3.4</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2022-01-24 18:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CitizenResponse                                  \\\n",
       "     12345678910» 12345678910».1 12345678910».2   \n",
       "0                4             NaN             III   \n",
       "1              NaN             NaN             NaN   \n",
       "2               15             NaN              IV   \n",
       "3              NaN             NaN               F   \n",
       "4              NaN             NaN             NaN   \n",
       "5              NaN             NaN             NaN   \n",
       "6              NaN             NaN             NaN   \n",
       "7               13             NaN              IV   \n",
       "8              NaN             NaN             NaN   \n",
       "9              NaN             NaN             NaN   \n",
       "10             NaN             NaN             NaN   \n",
       "11              51             NaN              IV   \n",
       "12             NaN             NaN             NaN   \n",
       "13             NaN             NaN             NaN   \n",
       "14             NaN             NaN             NaN   \n",
       "15             NaN             NaN             NaN   \n",
       "16             NaN             NaN             NaN   \n",
       "17             NaN             NaN             NaN   \n",
       "18             NaN             NaN             NaN   \n",
       "19             NaN             NaN             NaN   \n",
       "20             NaN             NaN             NaN   \n",
       "21             NaN             NaN             NaN   \n",
       "22             NaN             NaN             NaN   \n",
       "23             NaN             NaN             NaN   \n",
       "24             NaN             NaN             NaN   \n",
       "25             NaN             NaN               F   \n",
       "26             NaN             NaN             NaN   \n",
       "27             NaN             NaN             NaN   \n",
       "28             NaN             NaN               F   \n",
       "29             NaN             NaN             NaN   \n",
       "30             NaN             NaN             NaN   \n",
       "31             NaN             NaN               F   \n",
       "32             NaN             NaN             NaN   \n",
       "33             NaN             NaN             NaN   \n",
       "34             NaN             NaN             NaN   \n",
       "35             NaN             NaN             NaN   \n",
       "36             NaN             NaN             NaN   \n",
       "37             NaN             NaN             NaN   \n",
       "38             NaN             NaN             NaN   \n",
       "39             NaN             NaN             NaN   \n",
       "40             NaN             NaN             NaN   \n",
       "41             NaN             NaN             NaN   \n",
       "42             NaN             NaN             NaN   \n",
       "43             NaN             NaN             NaN   \n",
       "44             NaN             NaN             NaN   \n",
       "45             NaN             NaN             NaN   \n",
       "46             NaN             NaN             NaN   \n",
       "47             NaN             NaN             NaN   \n",
       "48             NaN             NaN             NaN   \n",
       "49             NaN             NaN             NaN   \n",
       "50             NaN             NaN             NaN   \n",
       "51   12345678910»   12345678910»   12345678910»   \n",
       "52             NaN             NaN             NaN   \n",
       "\n",
       "                       Date & Time UTC Latitude degrees                  \\\n",
       "                         12345678910»    12345678910» 12345678910».1   \n",
       "0       2022-01-24 22:04:45.015min ago            34.89               N   \n",
       "1       2022-01-24 22:03:35.016min ago             2.82               S   \n",
       "2       2022-01-24 22:00:49.919min ago            46.01               N   \n",
       "3       2022-01-24 21:58:06.422min ago            19.23               N   \n",
       "4       2022-01-24 21:50:10.930min ago            33.27               S   \n",
       "5       2022-01-24 21:43:39.936min ago            37.09               N   \n",
       "6       2022-01-24 21:39:00.441min ago            28.55               N   \n",
       "7       2022-01-24 21:24:47.755min ago            33.29               S   \n",
       "8       2022-01-24 21:21:22.658min ago            35.42               N   \n",
       "9   2022-01-24 21:17:43.81hr 02min ago            58.35               S   \n",
       "10  2022-01-24 21:16:40.81hr 03min ago            19.36               S   \n",
       "11  2022-01-24 21:14:13.01hr 05min ago             8.84               S   \n",
       "12  2022-01-24 21:12:32.41hr 07min ago            38.47               N   \n",
       "13  2022-01-24 21:09:22.11hr 10min ago            37.84               N   \n",
       "14  2022-01-24 21:08:51.71hr 11min ago            17.97               N   \n",
       "15  2022-01-24 21:07:22.41hr 12min ago            46.20               N   \n",
       "16  2022-01-24 21:02:28.11hr 17min ago            19.23               N   \n",
       "17  2022-01-24 20:57:56.51hr 22min ago            19.22               N   \n",
       "18  2022-01-24 20:55:16.71hr 24min ago            18.51               N   \n",
       "19  2022-01-24 20:54:55.01hr 25min ago            19.19               N   \n",
       "20  2022-01-24 20:54:12.81hr 25min ago            18.51               N   \n",
       "21  2022-01-24 20:52:59.41hr 27min ago            19.81               N   \n",
       "22  2022-01-24 20:39:15.01hr 40min ago             9.17               N   \n",
       "23  2022-01-24 20:29:31.21hr 50min ago            42.83               N   \n",
       "24  2022-01-24 20:26:58.71hr 53min ago            18.52               N   \n",
       "25  2022-01-24 20:25:45.01hr 54min ago            37.59               S   \n",
       "26  2022-01-24 20:19:47.02hr 00min ago            21.71               S   \n",
       "27  2022-01-24 20:01:44.92hr 18min ago            18.51               N   \n",
       "28  2022-01-24 19:46:43.82hr 33min ago            38.45               N   \n",
       "29  2022-01-24 19:43:12.02hr 37min ago            16.60               N   \n",
       "30  2022-01-24 19:41:33.52hr 38min ago            19.10               N   \n",
       "31  2022-01-24 19:39:00.02hr 41min ago            29.79               N   \n",
       "32  2022-01-24 19:37:56.12hr 42min ago            31.68               N   \n",
       "33  2022-01-24 19:36:03.42hr 44min ago            35.47               N   \n",
       "34  2022-01-24 19:26:26.52hr 53min ago            18.17               N   \n",
       "35  2022-01-24 19:25:08.62hr 55min ago            33.36               N   \n",
       "36  2022-01-24 19:23:39.92hr 56min ago             3.63               N   \n",
       "37  2022-01-24 19:10:20.03hr 09min ago            37.19               N   \n",
       "38  2022-01-24 19:09:37.13hr 10min ago            42.65               N   \n",
       "39  2022-01-24 18:58:11.73hr 22min ago            33.33               S   \n",
       "40  2022-01-24 18:53:17.93hr 26min ago            35.71               S   \n",
       "41  2022-01-24 18:50:20.63hr 29min ago            18.47               N   \n",
       "42  2022-01-24 18:48:34.03hr 31min ago            42.83               N   \n",
       "43  2022-01-24 18:40:43.13hr 39min ago            18.51               N   \n",
       "44  2022-01-24 18:40:23.03hr 39min ago            20.11               S   \n",
       "45  2022-01-24 18:38:16.13hr 41min ago            18.50               N   \n",
       "46  2022-01-24 18:32:23.23hr 47min ago            18.50               N   \n",
       "47  2022-01-24 18:29:02.13hr 51min ago            45.49               N   \n",
       "48  2022-01-24 18:23:11.83hr 57min ago            63.30               N   \n",
       "49  2022-01-24 18:16:16.34hr 03min ago            18.45               N   \n",
       "50                                 NaN              NaN             NaN   \n",
       "51                       12345678910»    12345678910»   12345678910»   \n",
       "52                                 NaN              NaN             NaN   \n",
       "\n",
       "   Longitude degrees                       Depth km        Mag [+]  \\\n",
       "       12345678910» 12345678910».1  12345678910»  12345678910»   \n",
       "0              25.25               E              2             ML   \n",
       "1             129.42               E             10              M   \n",
       "2              15.13               E              0             ML   \n",
       "3             155.39               W             33             Ml   \n",
       "4             117.21               E              7             ML   \n",
       "5             120.99               W              6             Md   \n",
       "6              17.85               W             11             ML   \n",
       "7             117.00               E              2             mb   \n",
       "8              32.23               E              5             ML   \n",
       "9              25.30               W             33             mb   \n",
       "10            173.35               W            114             mb   \n",
       "11            116.15               E             10              M   \n",
       "12             39.23               E              2             ML   \n",
       "13             14.67               E             34             ML   \n",
       "14             66.51               W             13             Md   \n",
       "15              7.30               E              8             ML   \n",
       "16            155.39               W             32             Md   \n",
       "17            155.42               W             33             Ml   \n",
       "18             73.33               W              2              M   \n",
       "19             68.86               W             15              M   \n",
       "20             73.31               W              4              M   \n",
       "21             72.99               W              5              M   \n",
       "22             82.09               W             10              M   \n",
       "23              1.33               W             10             ML   \n",
       "24             73.33               W              2              M   \n",
       "25            179.66               W             20             mb   \n",
       "26             69.76               W             85              M   \n",
       "27             73.29               W              5              M   \n",
       "28             39.22               E              0             ML   \n",
       "29             94.46               W            103              M   \n",
       "30             64.64               W              9             Md   \n",
       "31             80.35               E             10              M   \n",
       "32            104.44               W              9             ML   \n",
       "33              3.67               W             22             ML   \n",
       "34             72.36               W              5              M   \n",
       "35            117.91               W             10             Ml   \n",
       "36            126.70               E             58             mb   \n",
       "37             30.93               E            104             ML   \n",
       "38             45.35               E              5             mb   \n",
       "39            117.00               E              3             ML   \n",
       "40            179.41               E            292              M   \n",
       "41             73.28               W              6              M   \n",
       "42              1.32               W              9             ML   \n",
       "43             73.32               W              4              M   \n",
       "44             69.15               W             94              M   \n",
       "45             73.27               W              6              M   \n",
       "46             73.30               W              5              M   \n",
       "47             10.25               E              8             ML   \n",
       "48            151.30               W             12             ML   \n",
       "49             73.30               W              3              M   \n",
       "50               NaN             NaN            NaN            NaN   \n",
       "51     12345678910»   12345678910»  12345678910»  12345678910»   \n",
       "52               NaN             NaN            NaN            NaN   \n",
       "\n",
       "   Region name [+]                  Last update [-] Unnamed: 12_level_0  \n",
       "     12345678910»                    12345678910»       12345678910»  \n",
       "0              3.5                    CRETE, GREECE    2022-01-24 22:14  \n",
       "1              4.4                 SERAM, INDONESIA    2022-01-24 22:10  \n",
       "2              2.5                         SLOVENIA    2022-01-24 22:14  \n",
       "3              3.0         ISLAND OF HAWAII, HAWAII    2022-01-24 22:17  \n",
       "4              3.6                WESTERN AUSTRALIA    2022-01-24 22:09  \n",
       "5              2.2               CENTRAL CALIFORNIA    2022-01-24 21:45  \n",
       "6              1.6     CANARY ISLANDS, SPAIN REGION    2022-01-24 21:44  \n",
       "7              4.8                WESTERN AUSTRALIA    2022-01-24 22:11  \n",
       "8              2.6                    CYPRUS REGION    2022-01-24 21:29  \n",
       "9              5.1    SOUTH SANDWICH ISLANDS REGION    2022-01-24 21:44  \n",
       "10             5.0                            TONGA    2022-01-24 21:42  \n",
       "11             4.7         LOMBOK REGION, INDONESIA    2022-01-24 21:20  \n",
       "12             2.8                   EASTERN TURKEY    2022-01-24 21:37  \n",
       "13             2.1                    SICILY, ITALY    2022-01-24 21:33  \n",
       "14             2.5               PUERTO RICO REGION    2022-01-24 21:20  \n",
       "15             1.3                      SWITZERLAND    2022-01-24 21:13  \n",
       "16             2.2         ISLAND OF HAWAII, HAWAII    2022-01-24 21:05  \n",
       "17             2.3         ISLAND OF HAWAII, HAWAII    2022-01-24 21:03  \n",
       "18             4.2                     HAITI REGION    2022-01-24 21:07  \n",
       "19             2.5        DOMINICAN REPUBLIC REGION    2022-01-24 21:36  \n",
       "20             4.0                     HAITI REGION    2022-01-24 21:03  \n",
       "21             4.3                     HAITI REGION    2022-01-24 21:00  \n",
       "22             3.6  PANAMA-COSTA RICA BORDER REGION    2022-01-24 20:41  \n",
       "23             1.8                         PYRENEES    2022-01-24 20:47  \n",
       "24             3.1                     HAITI REGION    2022-01-24 20:36  \n",
       "25             5.2       EAST OF NORTH ISLAND, N.Z.    2022-01-24 21:12  \n",
       "26             2.5               ANTOFAGASTA, CHILE    2022-01-24 20:47  \n",
       "27             4.6                     HAITI REGION    2022-01-24 20:10  \n",
       "28             3.0                   EASTERN TURKEY    2022-01-24 20:38  \n",
       "29             4.0                   OAXACA, MEXICO    2022-01-24 20:06  \n",
       "30             3.3            VIRGIN ISLANDS REGION    2022-01-24 20:27  \n",
       "31             4.3        NEPAL-INDIA BORDER REGION    2022-01-24 19:55  \n",
       "32             3.2                    WESTERN TEXAS    2022-01-24 20:14  \n",
       "33             2.0              STRAIT OF GIBRALTAR    2022-01-24 20:22  \n",
       "34             3.2                     HAITI REGION    2022-01-24 19:35  \n",
       "35             2.0   GULF OF SANTA CATALINA, CALIF.    2022-01-24 19:27  \n",
       "36             4.9      KEPULAUAN TALAUD, INDONESIA    2022-01-24 20:24  \n",
       "37             2.5                   WESTERN TURKEY    2022-01-24 19:24  \n",
       "38             3.8          CAUCASUS REGION, RUSSIA    2022-01-24 20:29  \n",
       "39             2.6                WESTERN AUSTRALIA    2022-01-24 19:05  \n",
       "40             3.6  OFF E. COAST OF N. ISLAND, N.Z.    2022-01-24 19:00  \n",
       "41             3.3                     HAITI REGION    2022-01-24 18:56  \n",
       "42             2.3                         PYRENEES    2022-01-24 19:04  \n",
       "43             3.7                     HAITI REGION    2022-01-24 18:48  \n",
       "44             2.8                  TARAPACA, CHILE    2022-01-24 18:52  \n",
       "45             3.6                     HAITI REGION    2022-01-24 18:44  \n",
       "46             3.6                     HAITI REGION    2022-01-24 18:39  \n",
       "47             2.0                   NORTHERN ITALY    2022-01-24 18:34  \n",
       "48             3.0                   CENTRAL ALASKA    2022-01-24 19:14  \n",
       "49             3.4                     HAITI REGION    2022-01-24 18:23  \n",
       "50             NaN                              NaN                 NaN  \n",
       "51   12345678910»                    12345678910»       12345678910»  \n",
       "52             NaN                              NaN                 NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the date, days, title, city, country of next 25 hackathon events as a Pandas dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://www.eventbrite.com.mx/d/online/hackathon/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GovTech Virtual Hackathon 2022',\n",
       " 'GovTech Virtual Hackathon 2022',\n",
       " 'DeveloperWeek 2022  Hackathon',\n",
       " 'DeveloperWeek 2022  Hackathon',\n",
       " 'RecruitaTH0n (Green Jobs) Virtual Hackathon 2022',\n",
       " 'RecruitaTH0n (Green Jobs) Virtual Hackathon 2022',\n",
       " 'FinTech Virtual Hackathon 2022',\n",
       " 'FinTech Virtual Hackathon 2022',\n",
       " 'HackHerTH.0n (IWD) 2022 - Virtual Hackathon',\n",
       " 'HackHerTH.0n (IWD) 2022 - Virtual Hackathon',\n",
       " 'TechTogether Miami',\n",
       " 'TechTogether Miami',\n",
       " 'TechTogether Atlanta',\n",
       " 'TechTogether Atlanta',\n",
       " 'Pearl Hacks 2022: Beginner Friendly Women and Nonbinary Hackathon',\n",
       " 'Pearl Hacks 2022: Beginner Friendly Women and Nonbinary Hackathon',\n",
       " 'NEAR Hackathon Launch Event',\n",
       " 'NEAR Hackathon Launch Event',\n",
       " 'NEAR Hackathon: Ideation Workshop',\n",
       " 'NEAR Hackathon: Ideation Workshop',\n",
       " 'TechTogether Chicago',\n",
       " 'TechTogether Chicago',\n",
       " 'Sports Tech  Virtual Hackathon 2022',\n",
       " 'Sports Tech  Virtual Hackathon 2022',\n",
       " 'NEAR Hackathon Finale and Prizegiving',\n",
       " 'NEAR Hackathon Finale and Prizegiving',\n",
       " 'eGaming Virtual Hackathon  2022',\n",
       " 'eGaming Virtual Hackathon  2022',\n",
       " 'Hackathon Intraemprendimiento / Intrapreneurship Hackathon',\n",
       " 'Hackathon Intraemprendimiento / Intrapreneurship Hackathon',\n",
       " 'Girls Who Start Hackathon 2022',\n",
       " 'Girls Who Start Hackathon 2022',\n",
       " 'PreHacks',\n",
       " 'PreHacks',\n",
       " 'RecruitaTH0n (Grads & Interns) Virtual Hackathon 2022',\n",
       " 'RecruitaTH0n (Grads & Interns) Virtual Hackathon 2022',\n",
       " 'Encode x Tezos: Intro to Blockchain',\n",
       " 'Encode x Tezos: Intro to Blockchain',\n",
       " 'AgriTech Virtual Hackathon 2022',\n",
       " 'AgriTech Virtual Hackathon 2022']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = soup.select('div.eds-is-hidden-accessible')\n",
    "event_name = [element.text for element in events]\n",
    "event_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fri, Feb 11, 2022 7:00 PM GMT (+00:00)',\n",
       " 'Fri, Feb 11, 2022 7:00 PM GMT (+00:00)',\n",
       " 'Mon, Jan 24, 2022 10:00 AM PST (-08:00)',\n",
       " 'Mon, Jan 24, 2022 10:00 AM PST (-08:00)',\n",
       " 'Fri, Jan 28, 2022 7:00 PM GMT (+00:00)',\n",
       " 'Fri, Jan 28, 2022 7:00 PM GMT (+00:00)',\n",
       " 'Fri, Apr 22, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Apr 22, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Mar 4, 2022 7:00 PM GMT (+00:00)',\n",
       " 'Fri, Mar 4, 2022 7:00 PM GMT (+00:00)',\n",
       " 'Fri, Feb 11, 2022 4:00 PM EST (-05:00)',\n",
       " 'Fri, Feb 11, 2022 4:00 PM EST (-05:00)',\n",
       " 'Fri, Jan 28, 2022 5:00 PM EST (-05:00)',\n",
       " 'Fri, Jan 28, 2022 5:00 PM EST (-05:00)',\n",
       " 'Fri, Feb 18, 2022 6:00 PM EST (-05:00)',\n",
       " 'Fri, Feb 18, 2022 6:00 PM EST (-05:00)',\n",
       " 'Wed, Feb 2, 2022 5:30 PM GMT (+00:00)',\n",
       " 'Wed, Feb 2, 2022 5:30 PM GMT (+00:00)',\n",
       " 'Tue, Feb 15, 2022 5:30 PM GMT (+00:00)',\n",
       " 'Tue, Feb 15, 2022 5:30 PM GMT (+00:00)',\n",
       " 'Fri, Feb 25, 2022 3:00 PM CST (-06:00)',\n",
       " 'Fri, Feb 25, 2022 3:00 PM CST (-06:00)',\n",
       " 'Fri, Jul 15, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Jul 15, 2022 7:00 PM BST (+01:00)',\n",
       " 'Tue, Mar 29, 2022 5:30 PM BST (+01:00)',\n",
       " 'Tue, Mar 29, 2022 5:30 PM BST (+01:00)',\n",
       " 'Fri, Aug 19, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Aug 19, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Feb 4, 2022 8:30 AM CST (-06:00)',\n",
       " 'Fri, Feb 4, 2022 8:30 AM CST (-06:00)',\n",
       " 'Sun, Feb 27, 2022 10:00 AM EST (-05:00)',\n",
       " 'Sun, Feb 27, 2022 10:00 AM EST (-05:00)',\n",
       " 'Sat, Feb 5, 2022 9:00 AM EST (-05:00) + 1 evento más',\n",
       " 'Sat, Feb 5, 2022 9:00 AM EST (-05:00) + 1 evento más',\n",
       " 'Fri, May 27, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, May 27, 2022 7:00 PM BST (+01:00)',\n",
       " 'Thu, Jan 27, 2022 4:30 PM GMT (+00:00)',\n",
       " 'Thu, Jan 27, 2022 4:30 PM GMT (+00:00)',\n",
       " 'Fri, Oct 14, 2022 7:00 PM BST (+01:00)',\n",
       " 'Fri, Oct 14, 2022 7:00 PM BST (+01:00)']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = soup.select('div[class=\"eds-event-card-content__sub-title eds-text-color--ui-orange eds-l-pad-bot-1 eds-l-pad-top-2 eds-text-weight--heavy eds-text-bm\"]' )\n",
    "date_clean = [element.text for element in date]\n",
    "date_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English — Wikipedia — The Free Encyclopedia',\n",
       " 'Nihongo — ウィキペディア — フリー百科事典',\n",
       " 'Russkiy — Википедия — Свободная энциклопедия',\n",
       " 'Deutsch — Wikipedia — Die freie Enzyklopädie',\n",
       " 'Español — Wikipedia — La enciclopedia libre',\n",
       " 'Français — Wikipédia — L’encyclopédie libre',\n",
       " \"Italiano — Wikipedia — L'enciclopedia libera\",\n",
       " 'Zhōngwén — 維基百科 — 自由的百科全書',\n",
       " 'Polski — Wikipedia — Wolna encyklopedia',\n",
       " 'Português — Wikipédia — A enciclopédia livre']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "languages = soup.select('a.link-box')\n",
    "languages_all = [element['title'].strip() for element in languages]\n",
    "languages_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6383000 articles',\n",
       " '1292000 記事',\n",
       " '1756000 статей',\n",
       " '2617000 Artikel',\n",
       " '1717000 artículos',\n",
       " '2362000 articles',\n",
       " '1718000 voci',\n",
       " '1231000 條目',\n",
       " '1490000 haseł',\n",
       " '1074000 artigos']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = soup.select('small')\n",
    "numbers_text = [element.text.strip().replace('\\xa0','').replace('+','') for element in numbers]\n",
    "numbers_text[0:10]\n",
    "\n",
    "#numbers = [element['ltr'] for element in languages]\n",
    "#numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki1 = \n",
    "name = [element.text for element in wiki1] \n",
    "clean_wiki1 = [text.strip().replace('\\n6','').replace('\\xa0','') for text in name]\n",
    "clean_wiki1\n",
    "\n",
    "name = [element.text for element in wiki2] \n",
    "clean_wiki2 = [text.strip().replace('\\n1','').replace('\\xa0','') for text in name]\n",
    "clean_wiki2\n",
    "\n",
    "name = [element.text for element in wiki3] \n",
    "clean_wiki3 = [text.strip().replace('\\n1','').replace('\\xa0','') for text in name]\n",
    "clean_wiki3\n",
    "\n",
    "name = [element.text for element in wiki4] \n",
    "clean_wiki4 = [text.strip().replace('\\n2','').replace('\\xa0','') for text in name]\n",
    "clean_wiki4\n",
    "\n",
    "name = [element.text for element in wiki5] \n",
    "clean_wiki5 = [text.strip().replace('\\n1','').replace('\\xa0','') for text in name]\n",
    "clean_wiki5\n",
    "De Pablo Gonzalez Uzeta para todos 05:29 PM\n",
    "name = [element.text for element in wiki8] \n",
    "clean_wiki8 = [text.strip().replace('\\n1','').replace('\\xa0','') for text in name]\n",
    "clean_wiki8\n",
    "\n",
    "name = [element.text for element in wiki9] \n",
    "clean_wiki9 = [text.strip().replace('\\n1','').replace('\\xa0','') for text in name]\n",
    "clean_wiki9\n",
    "\n",
    "name = [element.text for element in wiki10] \n",
    "clean_wiki10 = [text.strip().replace('\\n1','').replace('\\xa0','') for text in name]\n",
    "clean_wiki10\n",
    "\n",
    "print(clean_wiki1)\n",
    "print(clean_wiki2)\n",
    "print(clean_wiki3)\n",
    "print(clean_wiki4)\n",
    "print(clean_wiki5)\n",
    "print(clean_wiki6)\n",
    "print(clean_wiki7)\n",
    "print(clean_wiki8)\n",
    "print(clean_wiki9)\n",
    "print(clean_wiki10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "govuk = soup.select('a[class=\"govuk-link\"]')\n",
    "govuk_list = [element.text for element in govuk]\n",
    "govuk_list[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "html = requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "table = pd.read_html(html)\n",
    "len(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Speakers(millions)</th>\n",
       "      <th>Percentageof world pop.(March 2019)[10]</th>\n",
       "      <th>Language family</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>918</td>\n",
       "      <td>11.922%</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>480</td>\n",
       "      <td>5.994%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>379</td>\n",
       "      <td>4.922%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hindi (sanskritised Hindustani)[11]</td>\n",
       "      <td>341</td>\n",
       "      <td>4.429%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>300</td>\n",
       "      <td>4.000%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>Czech</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.139%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>Taʽizzi-Adeni Arabic</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.136%</td>\n",
       "      <td>Afroasiatic</td>\n",
       "      <td>Semitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>Uyghur</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.135%</td>\n",
       "      <td>Turkic</td>\n",
       "      <td>Karluk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>Eastern Min</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.134%</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>Sylheti</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.134%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                             Language Speakers(millions)  \\\n",
       "0      1                     Mandarin Chinese                918   \n",
       "1      2                              Spanish                480   \n",
       "2      3                              English                379   \n",
       "3      4  Hindi (sanskritised Hindustani)[11]                341   \n",
       "4      5                              Bengali                300   \n",
       "..   ...                                  ...                ...   \n",
       "86    87                                Czech               10.7   \n",
       "87    88                 Taʽizzi-Adeni Arabic               10.5   \n",
       "88    89                               Uyghur               10.4   \n",
       "89    90                          Eastern Min               10.3   \n",
       "90    91                              Sylheti               10.3   \n",
       "\n",
       "   Percentageof world pop.(March 2019)[10] Language family        Branch  \n",
       "0                                  11.922%    Sino-Tibetan       Sinitic  \n",
       "1                                   5.994%   Indo-European       Romance  \n",
       "2                                   4.922%   Indo-European      Germanic  \n",
       "3                                   4.429%   Indo-European    Indo-Aryan  \n",
       "4                                   4.000%   Indo-European    Indo-Aryan  \n",
       "..                                     ...             ...           ...  \n",
       "86                                  0.139%   Indo-European  Balto-Slavic  \n",
       "87                                  0.136%     Afroasiatic       Semitic  \n",
       "88                                  0.135%          Turkic        Karluk  \n",
       "89                                  0.134%    Sino-Tibetan       Sinitic  \n",
       "90                                  0.134%   Indo-European    Indo-Aryan  \n",
       "\n",
       "[91 rows x 6 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Speakers(millions)</th>\n",
       "      <th>Percentageof world pop.(March 2019)[10]</th>\n",
       "      <th>Language family</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>918</td>\n",
       "      <td>11.922%</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>480</td>\n",
       "      <td>5.994%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>379</td>\n",
       "      <td>4.922%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hindi (sanskritised Hindustani)[11]</td>\n",
       "      <td>341</td>\n",
       "      <td>4.429%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>300</td>\n",
       "      <td>4.000%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>221</td>\n",
       "      <td>2.870%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Russian</td>\n",
       "      <td>154</td>\n",
       "      <td>2.000%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>128</td>\n",
       "      <td>1.662%</td>\n",
       "      <td>Japonic</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Western Punjabi[12]</td>\n",
       "      <td>92.7</td>\n",
       "      <td>1.204%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Marathi</td>\n",
       "      <td>83.1</td>\n",
       "      <td>1.079%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Telugu</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.065%</td>\n",
       "      <td>Dravidian</td>\n",
       "      <td>South-Central</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                             Language Speakers(millions)  \\\n",
       "0      1                     Mandarin Chinese                918   \n",
       "1      2                              Spanish                480   \n",
       "2      3                              English                379   \n",
       "3      4  Hindi (sanskritised Hindustani)[11]                341   \n",
       "4      5                              Bengali                300   \n",
       "5      6                           Portuguese                221   \n",
       "6      7                              Russian                154   \n",
       "7      8                             Japanese                128   \n",
       "8      9                  Western Punjabi[12]               92.7   \n",
       "9     10                              Marathi               83.1   \n",
       "10    11                               Telugu               82.0   \n",
       "\n",
       "   Percentageof world pop.(March 2019)[10] Language family         Branch  \n",
       "0                                  11.922%    Sino-Tibetan        Sinitic  \n",
       "1                                   5.994%   Indo-European        Romance  \n",
       "2                                   4.922%   Indo-European       Germanic  \n",
       "3                                   4.429%   Indo-European     Indo-Aryan  \n",
       "4                                   4.000%   Indo-European     Indo-Aryan  \n",
       "5                                   2.870%   Indo-European        Romance  \n",
       "6                                   2.000%   Indo-European   Balto-Slavic  \n",
       "7                                   1.662%         Japonic       Japanese  \n",
       "8                                   1.204%   Indo-European     Indo-Aryan  \n",
       "9                                   1.079%   Indo-European     Indo-Aryan  \n",
       "10                                  1.065%       Dravidian  South-Central  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(table[1])\n",
    "df.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
